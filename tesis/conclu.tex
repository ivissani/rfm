%!TEX root = tesis.tex
\chapter{Conclusiones y trabajo futuro}
\label{conclu}


\section{Conclusiones}

En el presente trabajo desarrollamos una herramienta de \ssolving paralelo y distribuido, orientada en particular a la verificación automática de propiedades sobre modelos formales de sistemas. Adoptamos un enfoque \emph{divide-and-conquer}, basado en una técnica conocida, para el particionamiento recursivo de subproblemas difíciles. Lo implementamos sobre una arquitectura original, dando respuesta a los aspectos cruciales de escalabilidad, usabilidad y automatización. Identificamos un factor limitante para la eficiencia del enfoque de particionamiento. Propusimos una solución basada en herencia de cláusulas aprendidas. Diseñamos e implementamos diversos criterios y evaluamos su desempeño.

\medskip

Las principales conclusiones respecto de la herramienta paralela y distribuida propiamente dicha son:

\begin{itemize}

\item La arquitectura resultó sólida y robusta, escalando sin inconvenientes al orden del centenar de \ws sobre decenas de equipos.

\item Para esa cantidad de \emph{hardware}, los (escasos pero cruciales) componentes centralizados no presentaron evidencia alguna de saturación. Incluso para corridas de problemas grandes se observó en esos puntos amplia capacidad ociosa.

\item Se identificaron correctamente los principales desafíos a resolver para lograr una operación 100\% automatizada. Se diseñaron soluciones pragmáticas, logrando convergencia y resultados satisfactorios para un banco de problemas con características disímiles, en distintos tamaños y grados de dificultad.

\end{itemize}



Las principales conclusiones respecto de la implementación y evaluación de cláusulas aprendidas en la herramienta distribuida son:

\begin{itemize}

\item La herencia de cláusulas aprendidas efectivamente permitió mejorar la eficiencia del análisis distribuido.

\item El grado en que eso ocurre parece depender fuertemente del problema.

\item Tanto para problemas donde la mejora es significativa como para aquellos donde no lo es, el grado de mejora tiende a aumentar junto con el tamaño de la instancia.

\item Es posible implementar un esquema de reuso de cláusulas aprendidas sin atentar contra la escalabilidad del sistema.

\item De los criterios de selección de cláusulas que evaluamos, el que logró mejores resultados globales fue aquel que retiene las cláusulas de tamaño menor o igual a 6, sin hechos.

\item Las mejoras en la eficiencia logradas gracias a la herencia de cláusulas aprendidas, si bien son significativas, no resuelven por completo el problema del retrabajo. Hay casos en que la eficiencia obtenida, a pesar de mejorar visiblemente respecto de la versión sin learning, sigue distando considerablemente del ideal lineal.

\end{itemize}



%[* Usando ese criterio, sobre los casos de estudio considerados el prototipo con herencia de cláusulas aprendidas logró un \emph{speedup} de ... [?]]




%Entre los aportes originales de esta tesis cabe destacar:
%
%\begin{itemize}
%
%\item \ldots
%
%\item \ldots
%
%\item \ldots
%
%\end{itemize}


\section{Trabajo futuro}

\subsubsection{Mejoras en la estrategia automatizada de toma de decisiones}

Uno de los aspectos más importantes a seguir refinando es la estrategia automática de toma de decisiones que hace posible la operación no supervisada del sistema. La versión actual logra evitar la mayor parte de los errores más evidentes, y así resulta capaz de llevar a buen puerto verificaciones breves, medianas y muy largas de propiedades muy diversas. Sin embargo, hay diversas capacidades que podrían ser mejoradas en futuras versiones.

Ante todo, los parámetros numéricos fijos restantes que se describieron en la sección~\ref{estrategia:implementada} deberían ser reemplazados por mecanismos autoajustables. También podrían refinarse los algoritmos y las métricas utilizadas para los mecanismos que ya son autoajustables. En particular:

\begin{itemize}
	\item Además de métricas directas (como la cantidad de problemas producidos y consumidos) y sus derivadas de primer orden (tasas de producción y consumo sobre tiempo), considerar también las de segundo orden (velocidad de estas últimas, i.e. aceleración de las primeras).
	\item Interpretar dichas métricas para determinar automáticamente la fase o etapa de la corrida en la que el sistema se encuentra (\emph{ramp-up}, meseta, \emph{ramp-down}, etc.), puesto que son varios los comportamientos que podrían beneficiarse variando en función de este conocimiento.
	\item Mejorar la estimación --y posiblemente la definición-- de ``progreso'', observando con mayor cuidado las métricas extendidas antedichas.
	\item El nivel de agresividad al partir --cuántas variables levantar, cuántos subproblemas generar como máximo en cada momento dado-- debería ser un parámetro dinámico que se autoajuste por retroalimentación en base al estado de las colas, la etapa actual de la corrida, etc.
	\item Utilizar información histórica para lograr algún grado de predecibilidad respecto de qué subproblemas tienen mayor probabilidad de ser los más difíciles de su camada, para así partirlos más temprano.
	\end{itemize}


\subsubsection{Evaluar la herramienta en \emph{clusters} más grandes}

Sería importante obtener acceso a (y cantidad suficiente de tiempo de cómputo en) grandes cantidades de \emph{hardware}. En primer lugar, para medir cómo escala el rendimiento conforme se agregan más y más \ws.

También sería interesante forzar la llegada al punto en que los componentes centralizados sí se conviertan en un factor limitante, para poder determinar si eso ocurre, por ejemplo, para cientos o para miles de \ws, y para observar si surgen otros factores limitantes que no hayamos imaginado.


\subsubsection{Diseñar y evaluar nuevos criterios de aprendizaje}

Ante todo sería necesario correr más experimentos, sobre una mayor diversidad de casos de estudio y para \emph{scopes} más grandes; esto último requiere abundante tiempo de cómputo.

Una ventaja en este sentido es el haber confirmado que ciertos criterios de aprendizaje no resultan beneficiosos. Dado que esos criterios solían ser los que más demoraban, su eliminación permitirá ahorrar tiempo de cómputo que podrá invertirse en la evaluación de nuevos criterios, diseñados en base a los que dieron mejores resultados.


\subsubsection{Análisis de conflictos, \emph{backjumping} y eliminación de subproblemas}

Sería importante pensar cómo llevar a cabo, a nivel distribuido, algo equivalente al análisis de conflictos que realizan las herramientas secuenciales (véase sección~\ref{backjumping}) de modo que permita lograr podas análogas a las que en secuencial se logran por medio del \emph{backtracking} no cronológico.

En la implementación distribuida, esto podría complementar el enfoque CDCL al permitirnos demostrar, durante o tras el análisis de un subproblema, que cierta cantidad de \emph{otros} subproblemas (como ser hermanos, primos o incluso ancestros) son necesariamente insatisfacibles, y así poder eliminarlos de las colas de pendientes y/o abortar sus análisis en curso, de haberlos.


\subsubsection{Interfaz más práctica para la toma de decisiones manual}

El mecanismo actual, basado en una consola interactiva, resulta de suma utilidad para intervenciones esporádicas en momentos clave de una corrida por lo demás automática. También permite controlar una corrida en forma totalmente manual, aunque esto no resulta del todo práctico debido a la gran cantidad de comandos involucrados y su extensión.

Sería mucho más amigable contar con algún tipo de interfaz gráfica en la que las tareas puedan arrastrarse entre \ws, partirse con un \emph{clic} sin necesidad de tipear largos identificadores de subproblema, etc.



